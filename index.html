<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
    <!-- webpage font coding -->
    <meta charset="utf-8">

    <!-- make the web compatiable for different browsers (IEedge first)-->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- make the website display flexiable for any devices -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- add page title -->
    <title>Yang's Homepage</title>

    <!-- add link subnail icon -->
	<link rel="shortcut icon" href="favicon.png" type="image/x-icon">
    
    <!-- import stylesheet (.css) fron outside -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900">
    <link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/styles.css">
</head>

<body>
    <!-- MOBILE MENU TOGGLE -->
    <!-- hide menu-toggle for PC, show only for mobile devices -->
    <!-- class 'shadow-large' controls the shadow of the box -->
    <!-- class 'fa' & 'fa-bars' are both fonts in /css/font-awesome.css-->
    <div id="mobile-menu-open" class="shadow-large">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>

    <!-- the header of the webpage -->
    <header>
        <div id="mobile-menu-close">
            <span>Close</span> <i class="fa fa-times" aria-hidden="true"></i>
        </div>
        <ul class="left-animation">
            <li>
                <a href="#about" class="menu-button">About &nbsp &nbsp &nbsp</a>
            </li>
            <li>
                <a href="#experience" class="menu-button">Experience &nbsp &nbsp &nbsp</a>
            </li>
            <li>
                <a href="#education" class="menu-button">Education &nbsp &nbsp &nbsp</a>
            </li>
            <li>
                <a href="#projects" class="menu-button">Projects &nbsp &nbsp &nbsp</a>
            </li>
            <li>
                <a href="#skills" class="menu-button">Skills &nbsp &nbsp &nbsp</a>
            </li>
            <li>
                <a href="#contact" class="menu-button">Contact</a>
            </li>
                &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp
            <li>
                <a href="./CV.pdf" download="YangJiaoCV.pdf" class="btn-rounded-white no-scroll">Download Resume</a>
            </li>
            
        </ul>
        
        
    </header>
    <!-- End header -->
    <div id="lead">
        <div id="lead-content">
            <h1 class="top-animation">Yang Jiao</h1>
            <h2 class="down-animation">AI Research Engineer, Ph.D.</h2>
            <a href="./CV.pdf" download="YangJiaoCV.pdf" class="btn-rounded-white">Download Resume</a>
            <!-- <a href="#" class="btn-rounded-white">Download Resume</a> -->
        </div>
        <!-- End #lead-content -->

        <div id="lead-overlay"></div>

        <div id="lead-down">
            <span>
                <i class="fa fa-chevron-down" aria-hidden="true"></i>
            </span>
        </div>
        <!-- End #lead-down -->
    </div>
    <!-- End #lead -->

    <div id="about">
        <div class="container">
            <div class="row">
                <div class="col-md-3">
                    <p>
                        <br><br><br>
                    </p>
                    <p> 
                        <img src="./images/photo.png" width=150px>
                    </p>
                    
                </div>
                <div class="col-md-9">
                    <p>
                        <h2 class="heading">About</h2>
                        Yang Jiao is an research engineer of artifical intelligence (AI), with research interest in the filed of computer vision, deep learning, neural networks, particulary in digital image processing (low-level) and image/video understanding (high-level) and their applications in optical/scene flow estimation, fine-grained visual categorization (FGVC), multi-modality facial expression recognition (FER), high dynamic range (HDR) and synthetic aperture radar (SAR) image enhancement. 
                        <br><br>
                        Jiao studied in the School of Electrical Engineering (EE) in Xidian University when he is a undergraduate student. Then he did research in the School of Artifical Intelligence (SAI) and the Department of Electrical and Computer Engineering (ECE) for Ph.D., in Xidian University and the Johns Hopkins University.
                        <br><br>
                        He earned his B.S. and Ph.D. degrees in Xidian University in 2015 and 2021 respectively - all in circuit and system, electronical science and technology.
                    </p>
                </div>
            </div>
        </div>
    </div>
    <!-- End #about -->

    <div id="experience" class="background-alt">
        <h2 class="heading">Education</h2>
        <div id="experience-timeline">
            <!-- Edu. BS at Xidian-->
            <div data-date="Sept. 2011 – July 2015<br>Xi'an, Shaanxi, China">
                <h3>Xidian University</h3>
                <h4>B.S. in Electrical Engineering (EE)</h4>
                <p>
                    Studied in the school of EE, major with Circuit and System. <br>Finished course work about science and engineering, did research of video stabilization.
                </p>
            </div>

            <!-- Edu. MS at Xidian-->
            <div data-date="Sept. 2015 – July 2016<br>Xi'an, Shaanxi, China">
                <h3>Xidian University</h3>
                <h4>M.S. in Artificail Intelligence (AI)</h4>
                <p>
                    Studied in the school of EE, major with Circuit and System. Did research about HDR SAR image enhancement and its satellite applications. Adviced by <a href="https://www.xidian.edu.cn/info/1020/3063.htm" target="_blank">Prof. Guangming Shi</a> and <a href="https://web.xidian.edu.cn/niuyi/" target="_blank">Prof. Yi Niu</a>.
                </p>
            </div>

            <!-- Edu. PhD at Xidian-->
            <div data-date="Sept. 2016 – Dec. 2021<br>Xi'an, Shaanxi, China">
                <h3>Xidian University</h3>
                <h4>Ph.D. in Artificail Intelligence (AI)</h4>
                <p>
                    Concentrated on pattern recognition, image understanding, deep learning and neural networks with its applications, e.g. fine-grained visual categorization and multi-modality facial expression recognition. Adviced by <a href="https://www.xidian.edu.cn/info/1020/3063.htm" target="_blank">Prof. Guangming Shi</a> and <a href="https://web.xidian.edu.cn/niuyi/" target="_blank">Prof. Yi Niu</a>.
                </p>
            </div>
            <!-- Edu. 4 at JHU -->
            <div data-date="Sept. 2019 – Sept. 2021<br>Baltimore, MD, U.S.">
                <h3>Johns Hopkins University</h3>
                <h4>VIS Ph.D. in Electrical and Computer Engineering (ECE)</h4>
                <p>
                    Concentrated on video understanding, motion consistency anaysis with its deep learning application of optical flow and scene flow estimation.
                    Adviced by <a href="https://thanglong.ece.jhu.edu/" target="_blank">Prof. Trac D. Tran</a>.
                </p>
            </div>
        </div>
    </div>
    <!-- End #experience -->

    <div id="education">
        <h2 class="heading">Experience</h2>
        <!-- Experience 1 -->
        <div class="education-block">
            <h3>Xidian Undergraduate Student Union</h3>
            <span class="education-date"> 2011 - 2014</span>
            <h4></h4>
            <p>
                Joined Xidian University Student Union in 2011 and hosted campus activities as the vice president & head of Dept. of Multi-Media Technology.
            </p>
        </div>

        <!-- Experience 2 -->
        <div class="education-block">
            <h3>Optoelectronic Imaging and Brain-Inspired Perception Laborotary <br>(OIBP)</h3>
            <span class="education-date"> 2015 - 2021</span>
            <h4></h4>
            <p>
                Joined OIBP in 2015 as a fresh graduate student and studied for 6 years. Love all the members here and appreciate them for the contribution.
            </p>
        </div>

        <!-- Experience 3 -->
        <div class="education-block">
            <h3>Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education (IPIU)</h3>
            <span class="education-date"> 2016 - 2021</span>
            <p>
                &nbsp<br>
                Research on neural networks, image understanding.
            </p>
        </div>

        <!-- Experience 4 -->
        <div class="education-block">
            <h3>Scholarship Under the State Scholarship Fund (by CSC)</h3>
            <span class="education-date"> 2019 - 2021</span>
            <h4></h4>
            <p>
                Awarded a scholarship under the State Scholarship Fund to pursue Ph.D. study in the U.S.. The awardee was selected through a rigid academia evaluation process organized by China Scholarship Concil (CSC).
            </p>
        </div>

        <!-- Experience 5 -->
        <div class="education-block">
            <h3>Xidian Guangzhou Institute of Technology</h3>
            <span class="education-date"> 2021</span>
            <h4></h4>
            <p>
                Research on optical flow, robotics.
            </p>
        </div>

        <!-- Experience 6 -->
        <div class="education-block">
            <h3>Huawei Technologies Co., Ltd.</h3>
            <span class="education-date">2022 - present</span>
            <h4></h4>
            <p>
                Research on deep learning, multi-media for HMS.
            </p>
        </div>
        
    </div>
    <!-- End #education -->
    
    <div id="projects" class="background-alt">
        <h2 class="heading">Papers & Projects</h2>
        <div class="container">
            <div class="row">

                <!-- Paper #2021-1 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2021_EffiScene.png" height=300px>
                    </div>
                    <div class="project-info">
                        <h3>EffiScene: Efficient Per-Pixel Rigidity Inference for Unsupervised Joint Learning of Optical Flow, Depth, Camera Pose and Motion Segmentation</h3>
                        <p>
                            We address the challenging unsupervised scene flow estimation problem by jointly learning four low-level vision sub-tasks: optical flow F, stereo-depth D, camera pose P and motion segmentation.
                        </p>
                        <!-- enter citation info -->
                        <a onclick="showCitation('Yang Jiao, Trac D. Tran, Guangming Shi; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, pp. 5538-5547')">Cite</a>

                        &nbsp &nbsp &nbsp &nbsp &nbsp
                        <!-- enter paper link -->    
                        <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Jiao_EffiScene_Efficient_Per-Pixel_Rigidity_Inference_for_Unsupervised_Joint_Learning_of_CVPR_2021_paper.html" target="_blank">View Paper</a>

                    </div>
                </div>

                <!-- Proj #2021-2 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2021_EmotionUI.png" />
                    </div>
                    <div class="project-info">
                        <h3>EmotionUI</h3>
                        <p>
                            A software for multimodalty 2D+3D facial expression recognition (FER). EmotionUI provides a user friendly interface for solving real-time FER task, including a full technique pipeline, e.g. face detection, pre-processing, 2D FER, 3D FER inference. And it supports customize data collection & training.
                        </p>
                        <a href="https://github.com/JohnnieXDU/EmotionUI" target="_blank">View Project</a>
                    </div>
                </div>

                <!-- Paper #2021-3 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2021_FGVC.png" height=300px>
                    </div>
                    <div class="project-info">
                        <h3>Attention Shift based Deep Neural Network for Fine Grained Visual Categorization</h3>
                        <p>
                            We propose a novel end-to-end FGVC network structure named Attention-Shift based Deep Neural Network (AS-DNN) to locate the discriminative re- gions automatically and encode the semantic correlations iteratively for FGVC task.
                        </p>
                        <!-- enter citation info -->
                        <a onclick="showCitation('Yi Niu, Yang Jiao, Guangming Shi. Attention Shift based Deep Neural Network for Fine Grained Visual Categorization. Pattern Recognition, vol. 116, p. 107947, 2021.')">Cite</a>

                        &nbsp &nbsp &nbsp &nbsp &nbsp
                        <!-- enter paper link -->    
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320321001345" target="_blank">View Paper</a>
                    </div>
                </div>

                <!-- Paper #2018-4 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2018_EMRD.png" height=300px>
                    </div>
                    <div class="project-info">
                        <h3>Dynamic Range Reduction of SAR Image via Global Optimum Entropy Maximization With Reflectivity-Distortion Constraint</h3>
                        <p>
                            We introduce a new SAR image visualization algorithm to map the high dynamic range SAR amplitude values to low dynamic range displays via reflectivity distortion preserved entropy maximization.
                        </p>
                        <!-- enter citation info -->
                        <a onclick="showCitation('Yang Jiao, Yi Niu, Lin Liu, Guanghui Zhao, Guangming Shi, Fu Li. Dynamic range reduction of SAR image via global optimum entropy maximization with reflectivity distortion constraint. IEEE Transactions on Geoscience and Remote Sensing, vol. 56, no. 5, pp. 2526 2538, 2018.')">Cite</a>

                        &nbsp &nbsp &nbsp &nbsp &nbsp
                        <!-- enter paper link -->    
                        <a href="https://ieeexplore.ieee.org/document/8265622" target="_blank">View Paper</a>
                    </div>
                </div>

                <!-- Paper #2021-5 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2021_MFR.png" height=300px>
                    </div>
                    <div class="project-info">
                        <h3>Optical Flow Estimation via Motion Feature Recovery</h3>
                        <p>
                            We discover the Vanishing Cost Volume Problem in optical flow, and propose a novel iterative Motion Feature Recovery (MFR) method to address the the problem via modeling motion consistency across multiple frames.
                        </p>
                        <!-- enter citation info -->
                        <a onclick="showCitation('Yang Jiao, Guangming Shi, Trac D Tran. Optical Flow Estimation via Motion Feature Recovery[C]. IEEE International Conference on Image Processing (ICIP), 2021.')">Cite</a>

                        &nbsp &nbsp &nbsp &nbsp &nbsp
                        <!-- enter paper link -->    
                        <a href="https://arxiv.org/abs/2101.06333#:~:text=In%20each%20MFR%20iteration%2C%20invalid,features%20for%20lost%2Dinformation%20restoration." target="_blank">View Paper</a>
                    </div>
                </div>

                <!-- Paper #2019-6 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2018_FACNN.png" height=300px>
                    </div>
                    <div class="project-info">
                        <h3>Attention based Convolutional Neural Network for 2D+ 3D Facial Expression Recognition</h3>
                        <p>
                            We propose an advanced facial attention based convolutional neural network (FA-CNN) for 2D+3D FER to address the existing discriminative regions localization problem.
                        </p>
                        <!-- enter citation info -->
                        <a onclick="showCitation('Yang Jiao, Yi Niu, Yuting Zhang, Fu Li, Chunbo Zou, Guangming Shi. Facial Attention based Convolutional Neural Network for 2D+ 3D Facial Expression Recognition. IEEE Visual Communications and Image Processing (VCIP), pp. 1-4, 2019.')">Cite</a>

                        &nbsp &nbsp &nbsp &nbsp &nbsp
                        <!-- enter paper link -->    
                        <a href="https://ieeexplore.ieee.org/document/8965843" target="_blank">View Paper</a>
                    </div>
                </div>                

                <!-- Paper #2020-7 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2020_FER.png" height=300px>
                    </div>
                    <div class="project-info">
                        <h3>2D+ 3D Facial Expression Recognition via Discriminative Dynamic Range Enhancement and Multi-Scale Learning</h3>
                        <p>
                            We propose a novel Map Generation technique from the viewpoint of information theory, to boost the slight 3D expression differences from strong personality variations, and design Facial Attention for multi-scale learning.
                        </p>
                        <!-- enter citation info -->
                        <a onclick="showCitation('Yang Jiao, Yi Niu, Trac D Tran, Guangming Shi. 2D+ 3D Facial Expression Recognition via Discriminative Dynamic Range Enhancement and Multi-Scale Learning. arXiv preprint, arXiv:2011.08333. 2020, 2020.')">Cite</a>

                        &nbsp &nbsp &nbsp &nbsp &nbsp
                        <!-- enter paper link -->    
                        <a href="https://arxiv.org/abs/2011.08333" target="_blank">View Paper</a>
                    </div>
                </div>  

                <!-- Paper #2021-8 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2021_Fan.png" height=300px>
                    </div>
                    <div class="project-info">
                        <h3>A novel lossless compression framework for facial depth images in expression recognition</h3>
                        <p>
                            We propose a novel efficient lossless compression framework for facial depth images in expression recognition to reduce the storage size and save bandwidth.
                        </p>
                        <!-- enter citation info -->
                        <a onclick="showCitation('Chunxiao Fan, Fu Li, Yang Jiao, Xueliang Liu. A novel lossless compression framework for facial depth images in expression recognition[J]. Multimedia Tools and Applications, vol. 80, pp. 24173 24183, 2021.')">Cite</a>

                        &nbsp &nbsp &nbsp &nbsp &nbsp
                        <!-- enter paper link -->    
                        <a href="https://link.springer.com/article/10.1007%2Fs11042-021-10796-1" target="_blank">View Paper</a>
                    </div>
                </div>  

                <!-- Paper #2015-9 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2015_Linf.png" height=300px>
                    </div>
                    <div class="project-info">
                        <h3>The L_infinity constrained global optimal histogram equalization technique for real time imaging</h3>
                        <p>
                            We remodel the histogram equalization tone mapping task based on graphic theory which achieves the global optimal solutions for HDR to LDR imaging.
                        </p>
                        <!-- enter citation info -->
                        <a onclick="showCitation('Qiongwei Ren, Yi Niu, Lin Liu, Yang Jiao, Guangming Shi. The L_infinity constrained global optimal histogram equalization technique for real time imaging[C]. International Conference on Optical Instruments and Technology: Optoelectronic Imaging and Processing Technology, vol. 9622, pp. 962206, 2015.')">Cite</a>

                        &nbsp &nbsp &nbsp &nbsp &nbsp
                        <!-- enter paper link -->    
                        <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/9622/962206/The-L_infinity-constrained-global-optimal-histogram-equalization-technique-for-real/10.1117/12.2193251.short?SSO=1" target="_blank">View Paper</a>
                    </div>
                </div>  

                <!-- Proj #2018-10 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/2018_GF4.png" />
                    </div>
                    <div class="project-info">
                        <h3>GF-** Satellite Image Enhancement System</h3>
                        <p>
                            A software for GF-** Satellite Image Enhancement System, including functions such as multi-band super-large image (15k*15k x 5 band) denosing, single/multi-frame super resolution, have removal.
                        </p>
                        <a onclick="showWarnning('Project infomation is confidential.')">View Project</a>
                    </div>
                </div>

                <!-- Proj #2018-10 -->
                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/projects/patent.png" />
                    </div>
                    <div class="patent-info">
                        <h3>Patents</h3>
                        <p>
                            <li>人脸表情分类器的训练、人脸表情的识别方法和装置: CN112906629A[P]. 2021.</li>
                            <li>一种场景流估计、场景流估计模型的训练方法和装置: CN113160278A[P]. 2021.</li>
                            <li>基于注意力转移机制的细粒度图像分类方法: CN110598029A[P]. 2019.</li>
                            <li>基于概率统计与图像梯度信息的全局矢量获取方法: CN105263026A[P]. 2018.</li>
                            <li>基于子空间正交向量的峰电位检测方法: CN105962932A[P]. 2018.</li>
                            <li>基于无穷范数约束与最大熵原则的色调映射方法: CN104835121A[P]. 2017.</li>
                        </p>
                    </div>
                </div>

            </div>
        </div>
    </div>
    <!-- End #projects -->

    <div id="skills">
        <h2 class="heading">Skills</h2>
        <ul>
            <li>Python</li>
            <li>C</li>
            <li>C++</li>
            <li>JavaScript</li>
            <li>Matlab</li>
            <li>Qt</li>
            <li>Node.js</li>
            <li>PyTorch</li>
            <li>TensorFlow</li>
            <li>Latex</li>
            <li>Anaconda</li>
        </ul>
    </div>
    <!-- End #skills -->

    <div id="contact">
        <h2>Get in Touch</h2>
        <div id="contact-form">
            <form method="POST" action="https://formspree.io/f/xrgjbrzq">
                <input type="hidden" name="_subject" value="Contact request from personal website" />
                <input type="email" name="_replyto" placeholder="Your email" required>
                <textarea name="message" placeholder="Your message ..." required></textarea>
                <button type="submit">Send</button>
            </form>
        </div>
        <!-- End #contact-form -->
    </div>
    <!-- End #contact -->

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-sm-5 copyright">
                    <p>
                        Copyright &copy; 2022 Yang Jiao <br>
                        Email: yjiao.xdu@gmail.com &nbsp &nbsp &nbsp
                        Phone: +86 155-2920-9858
                    </p>
                    
                </div>
                <div class="col-sm-2 top">
                    <span id="to-top">
                        <i class="fa fa-chevron-up" aria-hidden="true"></i>
                    </span>
                </div>
                <div class="col-sm-5 social">
                    <ul>
                        <li>
                            <a onclick="showWarnning('+86 155-2920-9858')"><i class="fa fa-phone" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://github.com/JohnnieXDU" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://scholar.google.com/citations?user=o_O3QDgAAAAJ&hl=en" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://www.facebook.com/" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://twitter.com/" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
                        </li>

                    </ul>
                </div>
            </div>
        </div>
    </footer>
    <!-- End footer -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="js/scripts.min.js"></script>
</body>

</html>
